{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. Import file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0, 61.07372593840988, 74.09453421137081, 59.81638571495272, 51.07837115648854, 24.413111231467404, 81.9084855189009, 18.439088914585774, 55.57877292636101, 66.76076692189807, 56.08029957123981, 48.25971404805462, 63.702433234531945, 66.61080993352356, 92.65527507918802, 52.630789467763066], [61.07372593840988, 0.0, 16.0, 12.806248474865697, 28.160255680657446, 36.796738985948195, 34.0147027033899, 45.45327270945405, 42.15447781671598, 26.248809496813376, 20.12461179749811, 34.0147027033899, 4.0, 35.510561809129406, 32.7566787083184, 36.05551275463989], [74.09453421137081, 16.0, 0.0, 27.202941017470888, 43.73785545725808, 49.73932046178355, 20.518284528683193, 57.0087712549569, 57.28001396647874, 20.024984394500787, 35.17101079013795, 37.16180835212409, 16.492422502470642, 30.14962686336267, 28.0178514522438, 51.419840528729765], [59.81638571495272, 12.806248474865697, 27.202941017470888, 0.0, 17.0, 37.12142238654117, 46.52956049652737, 47.01063709417264, 30.083217912982647, 38.897300677553446, 8.06225774829855, 43.41658669218482, 10.770329614269007, 47.80167361086848, 33.60059523282288, 24.331050121192877], [51.07837115648854, 28.160255680657446, 43.73785545725808, 17.0, 0.0, 33.0, 62.03224967708329, 43.04648650006177, 14.422205101855956, 52.15361924162119, 9.055385138137417, 50.47771785649585, 27.294688127912362, 59.665735560705194, 48.33218389437829, 8.06225774829855], [24.413111231467404, 36.796738985948195, 49.73932046178355, 37.12142238654117, 33.0, 0.0, 59.033888572581766, 10.198039027185569, 42.720018726587654, 44.28317965096906, 35.17101079013795, 29.410882339705484, 39.6232255123179, 46.2709412050371, 68.8839603971781, 37.656340767525464], [81.9084855189009, 34.0147027033899, 20.518284528683193, 46.52956049652737, 62.03224967708329, 59.033888572581766, 0.0, 63.56886030125127, 76.15773105863909, 15.231546211727817, 54.12947441089743, 36.05551275463989, 35.84689665786984, 20.0, 44.27188724235731, 70.00714249274856], [18.439088914585774, 45.45327270945405, 57.0087712549569, 47.01063709417264, 43.04648650006177, 10.198039027185569, 63.56886030125127, 0.0, 51.97114584074513, 48.38388161361178, 45.35416188179427, 30.01666203960727, 48.60041152089147, 48.25971404805462, 78.00640999302557, 47.265209192385896], [55.57877292636101, 42.15447781671598, 57.28001396647874, 30.083217912982647, 14.422205101855956, 42.720018726587654, 76.15773105863909, 51.97114584074513, 0.0, 66.57326790837296, 22.135943621178654, 64.03124237432849, 40.80441152620633, 74.02702209328699, 57.271284253105414, 6.4031242374328485], [66.76076692189807, 26.248809496813376, 20.024984394500787, 38.897300677553446, 52.15361924162119, 44.28317965096906, 15.231546211727817, 48.38388161361178, 66.57326790837296, 0.0, 45.45327270945405, 21.2602916254693, 29.410882339705484, 10.198039027185569, 48.0, 60.207972893961475], [56.08029957123981, 20.12461179749811, 35.17101079013795, 8.06225774829855, 9.055385138137417, 35.17101079013795, 54.12947441089743, 45.35416188179427, 22.135943621178654, 45.45327270945405, 0.0, 47.01063709417264, 18.681541692269406, 53.75872022286245, 39.824615503479755, 16.278820596099706], [48.25971404805462, 34.0147027033899, 37.16180835212409, 43.41658669218482, 50.47771785649585, 29.410882339705484, 36.05551275463989, 30.01666203960727, 64.03124237432849, 21.2602916254693, 47.01063709417264, 0.0, 38.01315561749642, 18.439088914585774, 64.03124237432849, 57.8013840664737], [63.702433234531945, 4.0, 16.492422502470642, 10.770329614269007, 27.294688127912362, 39.6232255123179, 35.84689665786984, 48.60041152089147, 40.80441152620633, 29.410882339705484, 18.681541692269406, 38.01315561749642, 0.0, 38.948684188300895, 29.410882339705484, 34.92849839314596], [66.61080993352356, 35.510561809129406, 30.14962686336267, 47.80167361086848, 59.665735560705194, 46.2709412050371, 20.0, 48.25971404805462, 74.02702209328699, 10.198039027185569, 53.75872022286245, 18.439088914585774, 38.948684188300895, 0.0, 58.034472514187634, 67.62396025078685], [92.65527507918802, 32.7566787083184, 28.0178514522438, 33.60059523282288, 48.33218389437829, 68.8839603971781, 44.27188724235731, 78.00640999302557, 57.271284253105414, 48.0, 39.824615503479755, 64.03124237432849, 29.410882339705484, 58.034472514187634, 0.0, 53.45091205957107], [52.630789467763066, 36.05551275463989, 51.419840528729765, 24.331050121192877, 8.06225774829855, 37.656340767525464, 70.00714249274856, 47.265209192385896, 6.4031242374328485, 60.207972893961475, 16.278820596099706, 57.8013840664737, 34.92849839314596, 67.62396025078685, 53.45091205957107, 0.0]]\n"
     ]
    }
   ],
   "source": [
    "from instance_pyfile import *\n",
    "from support_pyfile import *\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Confige LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "safety_settings = [\n",
    "    {\n",
    "        \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
    "        \"threshold\": \"BLOCK_NONE\"\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
    "        \"threshold\": \"BLOCK_NONE\"\n",
    "    }, \n",
    "    {\n",
    "        \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
    "        \"threshold\": \"BLOCK_NONE\"\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
    "        \"threshold\": \"BLOCK_NONE\"\n",
    "    },\n",
    "]\n",
    "\n",
    "genai.configure(api_key='YOUR_API_KEY')\n",
    "\n",
    "model = genai.GenerativeModel(model_name='gemini-pro', safety_settings=safety_settings)\n",
    "\n",
    "config = genai.GenerationConfig(temperature=1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_cur = 999999999\n",
    "best_now = 999999990\n",
    "cur_temp = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Sample prompt constructions in paper\n",
    "- task_description: about TSP\n",
    "- in_context: instances from the population.\n",
    "- task_instruction: step-by-step instructions for LLM to follow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "description = 'You are given a list of points with coordinates: {' + list2str() + '}. Your task is to find a trace, with the shortest possible length, that trverses each point exactly once.\\n'\n",
    "\n",
    "in_context = 'Below are some previous traces and their lengths. The traces are arranged in descending order based on their lengths, where lower values are better.\\n'\n",
    "#in_context += pool2examples(Pool)                  ! NOTICE that each generation, Pool change.\n",
    "\n",
    "task_instruction = 'Please follow the instruction step-by-step to generate new trace:\\n'\n",
    "task_instruction += 'Step 1. Select two traces from the above traces.\\n'\n",
    "task_instruction += 'Step 2. Crossover the two traces chosen in Step 1 and generate a new trace.\\n'\n",
    "task_instruction += 'Step 3. Mutate the trace generated in Step 2 and generate a new trace.\\n'\n",
    "task_instruction += ('Step 4. Keep the generated trace generated in Step 3, repeat Step 1, 2, 3, until you have ' + str(N) + ' generated traces.\\n')\n",
    "task_instruction += 'Directly give me all the chosen traces at Step 1, bracketed them with <selection> and </selection>, and all the generated traces at Step 3, bracketed them with <res> and </res>. Not any explanation needed.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.5. Using workbook to write data to excel\n",
    "- Each generation, write to file some information: #gen, num_calls, best_found, worst_found, average\n",
    "- need to create workbook and newsheet at once then avoid overwritting.\n",
    "- each tsp_instances need different workbook and worksheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlsxwriter\n",
    "\n",
    "workbook = xlsxwriter.Workbook(\"trcd_rue_15_3.xlsx\")\n",
    "\n",
    "worksheet = workbook.add_worksheet(\"rue_15_tsp\")\n",
    "\n",
    "column_labels = ['#gen', 'num_calls', 'best_found', 'worst_found', 'average_sol']\n",
    "\n",
    "for i in range(len(column_labels)) :\n",
    "    worksheet.write(0, i, column_labels[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Algorithm1 (from paper):\n",
    "- each API call, provide all N child in the population as in-context learn for LLM\n",
    "- for 1 call, LLM try to generate N new offspring from the provided population.\n",
    "- Note with the Self-Adaption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for the API calls in generation 1: 20.397091150283813\n"
     ]
    }
   ],
   "source": [
    "Pool = randomFirstN(n, N)\n",
    "\n",
    "g = 1\n",
    "\n",
    "def proc() :\n",
    "    global Pool, g\n",
    "    global workbook, worksheet\n",
    "    num_calls = 0\n",
    "    \n",
    "    while g <= G :\n",
    "\n",
    "        if g % 50 == 0:\n",
    "            print(\"break after each 50 generations! \")\n",
    "            time.sleep(600)\n",
    "\n",
    "        num_calls = 0\n",
    "\n",
    "        start_gene = time.time()\n",
    "\n",
    "        prompt = description + (in_context + pool2examples(Pool)) + task_instruction\n",
    "\n",
    "        listOff = []\n",
    "        best_cur = Pool[N-1].length\n",
    "\n",
    "        while len(listOff) < N :\n",
    "\n",
    "            config = genai.GenerationConfig(temperature=cur_temp)\n",
    "\n",
    "            start_call = time.time()\n",
    "\n",
    "            \n",
    "            response = model.generate_content(contents=prompt, generation_config=config)\n",
    "\n",
    "            num_calls += 1\n",
    "\n",
    "            spent_call = time.time() - start_call\n",
    "\n",
    "            print(f\"Time for the API calls in generation {g}: {spent_call}\")\n",
    "\n",
    "            newGen = cutGenTrace(response.text)\n",
    "            for s in newGen:\n",
    "                if checkPermu(s, n) :\n",
    "                    listOff.append(s)\n",
    "        #P_sharp = transform(listOff[:N])\n",
    "\n",
    "        Pool = updatePool(Pool, listOff[:N], N)\n",
    "    \n",
    "        best_now = Pool[N-1].length\n",
    "\n",
    "        if check_stuck(best_cur, best_now, K=10):\n",
    "            cur_temp += 0.1\n",
    "            if cur_temp == 2.0 :\n",
    "                cur_temp = 1.5\n",
    "            \n",
    "            print(\"Self-Adaptation!\")\n",
    "\n",
    "        spent_gene = time.time() - start_gene\n",
    "        print(f\"Total time for the generation {g}: {spent_gene}\")\n",
    "        print(f\"best solution now is: {best_now}\")\n",
    "        print(f\"worst solution now is: {Pool[0].length}\")\n",
    "\n",
    "        worksheet.write(g, 0, g)\n",
    "        worksheet.write(g, 1, num_calls)\n",
    "        worksheet.write(g, 2, best_now)\n",
    "        worksheet.write(g, 3, Pool[0].length)\n",
    "        worksheet.write(g, 4, )\n",
    "        g += 1\n",
    "\n",
    "try:\n",
    "    proc()\n",
    "except:\n",
    "    if g < G:\n",
    "        proc()\n",
    "        \n",
    "print(Pool[N-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
